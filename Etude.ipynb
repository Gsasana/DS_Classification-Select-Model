{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La sélection de modèles est cruciale dans le processus de construction de bons modèles en Machine Learning supervisé.\n",
    "\n",
    " Elle aide à obtenir une bonne généralisation. Pour choisir un modèle, il faut comprendre les données, identifier les comportements pertinents et tenir compte des contraintes de mémoire et de temps. \n",
    " \n",
    " Par exemple, si les données montrent une linéarité, des modèles comme la régression logistique ou les SVM linéaires sont appropriés. Si l'interprétabilité est importante, des modèles simples comme la régression logistique ou les arbres de décision sont préférables. \n",
    " \n",
    " Pour des performances prédictives élevées avec des ressources suffisantes, les modèles d'ensemble comme RandomForest, XGBoost ou les réseaux de neurones sont recommandés. \n",
    " \n",
    " Une fois la méthode d'apprentissage choisie, la sélection du modèle se concentre sur les meilleurs hyperparamètres, qui sont les paramètres de la méthode d'apprentissage spécifiés avant l'entraînement. \n",
    " \n",
    " Trouver les bons hyperparamètres est crucial pour maximiser les performances du modèle. \n",
    " \n",
    " Enfin, sélectionner la meilleure méthode d'apprentissage parmi un ensemble de modèles appropriés se fait en fonction d'une métrique prédéterminée, adaptée au problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   blue           2000 non-null   int64  \n",
      " 2   clock_speed    2000 non-null   float64\n",
      " 3   dual_sim       2000 non-null   int64  \n",
      " 4   fc             2000 non-null   int64  \n",
      " 5   four_g         2000 non-null   int64  \n",
      " 6   int_memory     2000 non-null   int64  \n",
      " 7   m_dep          2000 non-null   float64\n",
      " 8   mobile_wt      2000 non-null   int64  \n",
      " 9   n_cores        2000 non-null   int64  \n",
      " 10  pc             2000 non-null   int64  \n",
      " 11  px_height      2000 non-null   int64  \n",
      " 12  px_width       2000 non-null   int64  \n",
      " 13  ram            2000 non-null   int64  \n",
      " 14  sc_h           2000 non-null   int64  \n",
      " 15  sc_w           2000 non-null   int64  \n",
      " 16  talk_time      2000 non-null   int64  \n",
      " 17  three_g        2000 non-null   int64  \n",
      " 18  touch_screen   2000 non-null   int64  \n",
      " 19  wifi           2000 non-null   int64  \n",
      " 20  price_range    2000 non-null   int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 328.3 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1238.518500</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>1.522250</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>4.309500</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>32.046500</td>\n",
       "      <td>0.501750</td>\n",
       "      <td>140.249000</td>\n",
       "      <td>4.520500</td>\n",
       "      <td>...</td>\n",
       "      <td>645.108000</td>\n",
       "      <td>1251.515500</td>\n",
       "      <td>2124.213000</td>\n",
       "      <td>12.306500</td>\n",
       "      <td>5.767000</td>\n",
       "      <td>11.011000</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>439.418206</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.816004</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>4.341444</td>\n",
       "      <td>0.499662</td>\n",
       "      <td>18.145715</td>\n",
       "      <td>0.288416</td>\n",
       "      <td>35.399655</td>\n",
       "      <td>2.287837</td>\n",
       "      <td>...</td>\n",
       "      <td>443.780811</td>\n",
       "      <td>432.199447</td>\n",
       "      <td>1084.732044</td>\n",
       "      <td>4.213245</td>\n",
       "      <td>4.356398</td>\n",
       "      <td>5.463955</td>\n",
       "      <td>0.426273</td>\n",
       "      <td>0.500116</td>\n",
       "      <td>0.500076</td>\n",
       "      <td>1.118314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>501.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>851.750000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>282.750000</td>\n",
       "      <td>874.750000</td>\n",
       "      <td>1207.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>2146.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1615.250000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>947.250000</td>\n",
       "      <td>1633.000000</td>\n",
       "      <td>3064.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>3998.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       battery_power       blue  clock_speed     dual_sim           fc  \\\n",
       "count    2000.000000  2000.0000  2000.000000  2000.000000  2000.000000   \n",
       "mean     1238.518500     0.4950     1.522250     0.509500     4.309500   \n",
       "std       439.418206     0.5001     0.816004     0.500035     4.341444   \n",
       "min       501.000000     0.0000     0.500000     0.000000     0.000000   \n",
       "25%       851.750000     0.0000     0.700000     0.000000     1.000000   \n",
       "50%      1226.000000     0.0000     1.500000     1.000000     3.000000   \n",
       "75%      1615.250000     1.0000     2.200000     1.000000     7.000000   \n",
       "max      1998.000000     1.0000     3.000000     1.000000    19.000000   \n",
       "\n",
       "            four_g   int_memory        m_dep    mobile_wt      n_cores  ...  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  ...   \n",
       "mean      0.521500    32.046500     0.501750   140.249000     4.520500  ...   \n",
       "std       0.499662    18.145715     0.288416    35.399655     2.287837  ...   \n",
       "min       0.000000     2.000000     0.100000    80.000000     1.000000  ...   \n",
       "25%       0.000000    16.000000     0.200000   109.000000     3.000000  ...   \n",
       "50%       1.000000    32.000000     0.500000   141.000000     4.000000  ...   \n",
       "75%       1.000000    48.000000     0.800000   170.000000     7.000000  ...   \n",
       "max       1.000000    64.000000     1.000000   200.000000     8.000000  ...   \n",
       "\n",
       "         px_height     px_width          ram         sc_h         sc_w  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean    645.108000  1251.515500  2124.213000    12.306500     5.767000   \n",
       "std     443.780811   432.199447  1084.732044     4.213245     4.356398   \n",
       "min       0.000000   500.000000   256.000000     5.000000     0.000000   \n",
       "25%     282.750000   874.750000  1207.500000     9.000000     2.000000   \n",
       "50%     564.000000  1247.000000  2146.500000    12.000000     5.000000   \n",
       "75%     947.250000  1633.000000  3064.500000    16.000000     9.000000   \n",
       "max    1960.000000  1998.000000  3998.000000    19.000000    18.000000   \n",
       "\n",
       "         talk_time      three_g  touch_screen         wifi  price_range  \n",
       "count  2000.000000  2000.000000   2000.000000  2000.000000  2000.000000  \n",
       "mean     11.011000     0.761500      0.503000     0.507000     1.500000  \n",
       "std       5.463955     0.426273      0.500116     0.500076     1.118314  \n",
       "min       2.000000     0.000000      0.000000     0.000000     0.000000  \n",
       "25%       6.000000     1.000000      0.000000     0.000000     0.750000  \n",
       "50%      11.000000     1.000000      1.000000     1.000000     1.500000  \n",
       "75%      16.000000     1.000000      1.000000     1.000000     2.250000  \n",
       "max      20.000000     1.000000      1.000000     1.000000     3.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd  \n",
    "\n",
    "# Lecture mobile_train.csv\n",
    "data = pd.read_csv('mobile_train.csv')\n",
    "\n",
    "print(data.info())\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Les variables sont numériques, certaines sont indicatrices. Les données semblent bien distribuées. Nous allons entraîner trois types de modèles : régression logistique, Random Forests et SVM. \n",
    "\n",
    "Nous devons normaliser les données en raison de leurs différences d'échelle. \n",
    "\n",
    "Pour évaluer les modèles, nous diviserons les données en ensembles d'entraînement, de validation et de test. \n",
    "\n",
    "Dans le cas de données chronologiques, nous séparerons les données selon le temps. \n",
    "\n",
    "Pour de petits ensembles de données, nous utiliserons simplement un ensemble d'entraînement et un ensemble de test pour évaluer le modèle final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sélection d'hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pour choisir les meilleurs hyperparamètres, on utilise la validation croisée. \n",
    "\n",
    "On divise l'ensemble d'entraînement en K ensembles plus petits. \n",
    "\n",
    "On entraîne des modèles sur K-1 ensembles avec différentes combinaisons d'hyperparamètres, puis on évalue leur performance sur l'ensemble retenu. \n",
    "\n",
    "On sélectionne ensuite les hyperparamètres offrant la meilleure performance moyenne. \n",
    "\n",
    "Enfin, on réentraîne le modèle avec ces hyperparamètres sur l'ensemble d'entraînement complet et on estime l'erreur de généralisation sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des packages\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation en 2 DF varaibles explicatives et cible\n",
    "X, y = data.drop('price_range', axis=1), data['price_range']\n",
    "\n",
    "# Création ensemble entrainement et test 75%/25%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# Normalisation\n",
    "X_train = MinMaxScaler().fit_transform(X_train)\n",
    "X_test = MinMaxScaler().fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création classifier LogisticRegression\n",
    "clf_lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Dictionnaire de params\n",
    "params_lr= {'solver': ['liblinear', 'lbfgs'], 'C': [10**(i) for i in range (-4,3)]}\n",
    "\n",
    "# instanciation de classe\n",
    "gridcv = GridSearchCV(clf_lr, param_grid=params_lr, scoring='accuracy', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.0001, 'solver': 'liblinear'}</td>\n",
       "      <td>0.558000</td>\n",
       "      <td>0.007483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.0001, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.260667</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.001, 'solver': 'liblinear'}</td>\n",
       "      <td>0.580667</td>\n",
       "      <td>0.008994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 0.001, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.310667</td>\n",
       "      <td>0.009978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 0.01, 'solver': 'liblinear'}</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 0.01, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.009798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 0.1, 'solver': 'liblinear'}</td>\n",
       "      <td>0.669333</td>\n",
       "      <td>0.022529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 0.1, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.016357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 1, 'solver': 'liblinear'}</td>\n",
       "      <td>0.759333</td>\n",
       "      <td>0.020997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 1, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'C': 10, 'solver': 'liblinear'}</td>\n",
       "      <td>0.819333</td>\n",
       "      <td>0.008219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'C': 10, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.004110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'C': 100, 'solver': 'liblinear'}</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.006182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'C': 100, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.009092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  params  mean_test_score  std_test_score\n",
       "0   {'C': 0.0001, 'solver': 'liblinear'}         0.558000        0.007483\n",
       "1       {'C': 0.0001, 'solver': 'lbfgs'}         0.260667        0.000943\n",
       "2    {'C': 0.001, 'solver': 'liblinear'}         0.580667        0.008994\n",
       "3        {'C': 0.001, 'solver': 'lbfgs'}         0.310667        0.009978\n",
       "4     {'C': 0.01, 'solver': 'liblinear'}         0.603333        0.013300\n",
       "5         {'C': 0.01, 'solver': 'lbfgs'}         0.646000        0.009798\n",
       "6      {'C': 0.1, 'solver': 'liblinear'}         0.669333        0.022529\n",
       "7          {'C': 0.1, 'solver': 'lbfgs'}         0.756667        0.016357\n",
       "8        {'C': 1, 'solver': 'liblinear'}         0.759333        0.020997\n",
       "9            {'C': 1, 'solver': 'lbfgs'}         0.884000        0.002828\n",
       "10      {'C': 10, 'solver': 'liblinear'}         0.819333        0.008219\n",
       "11          {'C': 10, 'solver': 'lbfgs'}         0.933333        0.004110\n",
       "12     {'C': 100, 'solver': 'liblinear'}         0.846667        0.006182\n",
       "13         {'C': 100, 'solver': 'lbfgs'}         0.956000        0.009092"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrainement de gridcv\n",
    "gridcv.fit(X_train, y_train)\n",
    "\n",
    "# Affichage résultat du gridsearch\n",
    "pd.DataFrame(gridcv.cv_results_)[['params', 'mean_test_score','std_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Le paramètre {'C': 100, 'solver': 'lbfgs'} est sélectionné car il a obtenu le meilleur score moyen lors de la validation croisée. \n",
    "\n",
    "Avec un score moyen de 0.956, il présente la meilleure performance parmi toutes les combinaisons d'hyperparamètres testées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation croisée imbriquée (Nested CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La validation croisée imbriquée est une méthode avancée pour sélectionner un algorithme de manière fiable. Voici comment elle fonctionne :\n",
    "\n",
    "- Division des données : Les données sont divisées en K ensembles plus petits pour la validation croisée.\n",
    "- Sélection des hyperparamètres : Pour chaque algorithme, un processus de validation croisée est effectué sur les K-1 ensembles restants pour sélectionner les meilleurs hyperparamètres.\n",
    "- Évaluation de la performance : Les meilleurs hyperparamètres sont utilisés pour estimer la performance de chaque algorithme sur l'ensemble mis de côté.\n",
    "- Sélection de l'algorithme : En calculant la moyenne et l'écart type des scores de validation sur les K ensembles, l'algorithme le plus performant et le plus stable est choisi.\n",
    "- Validation finale : En utilisant l'ensemble d'entraînement complet, le meilleur ensemble d'hyperparamètres est sélectionné par GridSearch. \n",
    "\n",
    "Enfin, l'erreur de généralisation est estimée en utilisant l'ensemble de test.\n",
    "Il est crucial de choisir un algorithme stable, dont la performance ne varie pas beaucoup avec des données légèrement différentes. Une attention particulière est portée à éviter toute fuite d'information lors du preprocessing, en le réalisant à l'intérieur de la boucle interne de la validation croisée. Cela garantit une estimation réaliste de l'erreur de généralisation finale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Numpy\n",
    "import numpy as np  \n",
    "\n",
    "# Instanciation de 3 classifieurs (LR, RFC, SVC)\n",
    "clf_lr = LogisticRegression(random_state=22, max_iter=2000)\n",
    "clf_rf = RandomForestClassifier(random_state=22)\n",
    "clf_svc = SVC(random_state=22)\n",
    "\n",
    "# création de 3 grilles de paramètres \n",
    "param_grid_lr = {'solver': ['liblinear', 'lbfgs'], 'C' : np.logspace(-4, 2, 9)}\n",
    "\n",
    "param_grid_rf = [{'n_estimators': [10, 50, 100, 250, 1000],\n",
    "                  'min_samples_leaf' : [1, 3, 5],\n",
    "                  'max_features' : ['sqrt', 'log2']}]\n",
    "\n",
    "param_grid_svc = [{'kernel': ['rbf'], 'C' : np.logspace(-4, 4, 9), 'gamma': np.logspace(-4, 0, 4)},\n",
    "                  {'kernel' : ['linear'], 'C': np.logspace(-4, 4, 9)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création dictionnaire gridcvs\n",
    "gridcv = {}\n",
    "\n",
    "# Instanciation pour chaque paire de modèle et gille d'un GridSearchCV et enregistrement dans gridcvs\n",
    "for pgrid, clf, name in zip((param_grid_lr, param_grid_rf, param_grid_svc),\n",
    "                            (clf_lr, clf_rf, clf_svc),\n",
    "                            ('LogisticRegression', 'RF', 'SVM')):\n",
    "    gcv = GridSearchCV(clf, pgrid, cv=3, refit=True)\n",
    "\n",
    "    gridcv[name] = gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: outer accuracy 95.67 +/- 1.23\n",
      "RF: outer accuracy 86.87 +/- 2.05\n",
      "SVM: outer accuracy 95.53 +/- 1.09\n"
     ]
    }
   ],
   "source": [
    "# Création objet StratifiedKFold : échantillonnage à 3 et shuffle=True\n",
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# Dictionnaire vide\n",
    "outer_scores = {}\n",
    "\n",
    "# boucle sur chq modèle de la grille\n",
    "for name, gs in gridcv.items():\n",
    "    # Validation croisée interne poyr chq modèle\n",
    "    nested_score = cross_val_score(gs, X_train, y_train, cv=outer_cv)\n",
    "    # enregistrement des scores de validation croisée\n",
    "    outer_scores[name] = nested_score\n",
    "    # Affichage des\n",
    "    print(f'{name}: outer accuracy {100*nested_score.mean():.2f} +/- {100*nested_score.std():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, nous devons sélectionner et entraîner le meilleur algorithme, celui qui affiche le taux moyen de précision le plus élevé et l'écart-type le plus faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param  {'C': 100.0, 'solver': 'lbfgs'}\n",
      "Training Accuracy : 98.53\n",
      "Test Accuracy : 97.20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Selection du modèle final à partir grille de recherche\n",
    "final_clf = gridcv['LogisticRegression']\n",
    "\n",
    "# Entrainement du modèle final sur ensemble entrainement\n",
    "final_clf.fit(X_train, y_train)\n",
    "\n",
    "# Affichae des meilleurs param sélectionnés\n",
    "print(f'Best param  {final_clf.best_params_}')\n",
    "\n",
    "# Calcule précision du modèle sur ensemble entrainement\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=final_clf.predict(X_train))\n",
    "\n",
    "# Calcule précision du modèle sur ensemble test\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=final_clf.predict(X_test))\n",
    "\n",
    "# Affichage précision du modèle sur ensemble entrainement\n",
    "print(f'Training Accuracy : {100*train_acc:.2f}')\n",
    "\n",
    "# Afichage précision du modèle sur ensemble test\n",
    "print(f'Test Accuracy : {100*test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Le score moyen obtenu par validation croisée sur l'ensemble d'entraînement peut souvent être une estimation pessimiste du modèle, car il n'est pas entraîné sur la totalité des données disponibles. \n",
    "\n",
    "En général, un modèle bénéficie d'une meilleure performance lorsque le nombre de données d'entraînement est plus élevé. \n",
    "\n",
    "Ainsi, une fois le modèle et les hyperparamètres sélectionnés, il est recommandé de ré-entraîner le modèle final sur l'ensemble des données disponibles avant de le déployer. \n",
    "\n",
    "Même si le modèle peut être évalué sur l'ensemble de test, une estimation approfondie de l'erreur de généralisation nous donne confiance dans les performances du modèle. \n",
    "\n",
    "De plus, étant donné que le modèle est également entraîné sur l'échantillon de test, il est probable qu'il fonctionne encore mieux en production. En résumé, ré-entraîner le modèle final sur toutes les données disponibles offre une opportunité d'améliorer ses performances et sa fiabilité avant son déploiement en production."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projetct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
